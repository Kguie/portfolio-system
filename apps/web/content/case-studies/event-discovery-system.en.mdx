# Event Discovery System

<div className="rounded-lg border border-cyan-300/30 bg-cyan-300/8 px-4 py-3 text-sm">
  <strong>TL;DR:</strong> We built a modular event discovery stack with normalized ingestion, fast facet search, and operational telemetry. The first version optimized reliability and query latency over feature breadth.
</div>

## Problem

Users could not reliably discover relevant local events because data quality and provider formats were inconsistent.

## Requirements

- Aggregate events from multiple providers.
- Normalize metadata (city, category, venue, time).
- Support low-latency search with facets.
- Keep ingestion and query paths observable in production.

## Architecture v1

```text
[Providers] -> [Ingestion Workers] -> [Normalizer] -> [Postgres]
                                               -> [Search Index]
[Mobile Expo] -> [Go API] -> [Search + Ranking] -> [FCM Notifications]
                                   |
                           [Metrics / Logs / Traces]
```

V1 separated ingestion from query serving so provider instability did not directly impact API latency.

## Key Trade-offs

- Chose strict normalization early; slower initial setup, cleaner query behavior later.
- Prioritized server-side ranking over client sorting; simpler clients, more backend complexity.
- Deferred advanced personalization to keep first release operationally stable.

## Observability

- Request-level tracing across API, ranking, and search calls.
- Error-rate and latency dashboards by route/provider.
- Ingestion lag alerts to detect stale event feeds.

## Roadmap

- Add intent-aware ranking signals.
- Improve deduplication for near-identical provider entries.
- Introduce relevance experiments with offline evaluation.
- Expand notification orchestration by user cohorts.
